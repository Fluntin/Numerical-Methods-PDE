{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a MATLAB program to numerically approximate:\n",
    "\n",
    "$$\n",
    "\\int_{\\epsilon<|x|<1}|\\nabla u(x)|^2 \\mathrm{~d} x=2 \\pi \\min _{v \\in \\hat{V}_\\epsilon} \\int_\\epsilon^1\\left(v^{\\prime}(r)\\right)^2 r \\mathrm{~d} r\n",
    "$$\n",
    "\n",
    "Using the finite element method as follows:\n",
    "\n",
    "$$\n",
    "U(x) = \\sum_{i=0}^N u_i \\varphi_i(x),\n",
    "$$\n",
    "$$u_0=1$$ \n",
    "$$u_N=0$$\n",
    "\n",
    "Where $\\varphi_i$ are piecewise linear basis functions satisfying $\\varphi_i(x_j)=0$ for $i \\neq j$ and $\\varphi_i(x_i)=1$ at the nodal points $x(i) = c + i(1-c)/N$.\n",
    "\n",
    "---\n",
    "\n",
    "- Show that the minimization problem:\n",
    "\n",
    "$$\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(U^{\\prime}(x)\\right)^2 \\mathrm{~d} x\n",
    "$$\n",
    "\n",
    "can be written as:\n",
    "\n",
    "$$\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\sum_{i=0}^N \\sum_{j=0}^N A_{i j} u_i u_j,\n",
    "$$\n",
    "\n",
    "and it leads to the equation system:\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{N-1} A_{i j} u_j = -A_{i 0}, \\quad i=1, \\ldots, N-1,\n",
    "$$\n",
    "\n",
    "where $A_{i j} = \\int_\\epsilon^1 x \\varphi_i^{\\prime}(x) \\varphi_j^{\\prime}(x) \\mathrm{d} x$. \n",
    "\n",
    "---\n",
    "\n",
    "- Display figures showing the solution $U$ for various values of $\\epsilon$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the minimum of an integral:\n",
    "\n",
    "$$\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(U^{\\prime}(x)\\right)^2 d x\n",
    "$$\n",
    "   - Here, $ U^{\\prime}(x) $ represents the derivative of a function $ U(x) $.\n",
    "   - The goal is to minimize this integral by appropriately choosing values for the parameters $ u_1, \\ldots, u_{N-1} $.\n",
    "\n",
    "**Transformation Using Basis Functions**:\n",
    "   First we transform $U^{\\prime}(x)$ into a linear combination of basis functions:\n",
    "\n",
    "$$\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(U^{\\prime}(x)\\right)^2 d x\n",
    "= \n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(\\sum_{i=0}^N u_i \\varphi_i^{\\prime}(x)\\right)^2 d x\n",
    "$$\n",
    "\n",
    "   - Here, $ \\varphi_i^{\\prime}(x) $ are the derivatives of basis functions $ \\varphi_i(x) $. These are predefined functions.\n",
    "   - The term $ \\sum_{i=0}^N u_i \\varphi_i^{\\prime}(x) $ is the representation of $ U^{\\prime}(x) $ as a weighted sum of these basis function derivatives. Each $ u_i $ is a coefficient that multiplies the corresponding basis function derivative $ \\varphi_i^{\\prime}(x) $.\n",
    "   - The optimization problem now is to choose the coefficients $ u_1, \\ldots, u_{N-1} $ in such a way that this new representation of the integral is minimized.\n",
    "\n",
    "**Expansion of the Square of the sum:**\n",
    "\n",
    "$$\n",
    "\\left(\\sum_{i=0}^N u_i \\varphi_i^{\\prime}(x)\\right)^2 =\\left(\\sum_{i=0}^N u_i \\varphi_i^{\\prime}(x)\\right) \\cdot \\left(\\sum_{j=0}^N u_j \\varphi_j^{\\prime}(x)\\right) \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(\\sum_{i=0}^N u_i \\varphi_i^{\\prime}(x)\\right)^2 d x\n",
    "= \n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(\\sum_{j=0}^N \\sum_{i=0}^N u_i u_j \\varphi_i^{\\prime}(x) \\varphi_j^{\\prime}(x)\\right) d x\n",
    "$$\n",
    "\n",
    "- This double sum represents all combinations of the pairwise products of the terms $u_i \\varphi_i^{\\prime}(x) $ and $u_j \\varphi_j^{\\prime}(x) $.\n",
    "- Essentially, every term in the original sum is multiplied by every other term, including itself.\n",
    "\n",
    "**Separating the integral from the coefficients $u_i$ and $u_j$:**\n",
    "$$\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(\\sum_{j=0}^N \\sum_{i=0}^N u_i u_j \\varphi_i^{\\prime}(x) \\varphi_j^{\\prime}(x)\\right) d x\n",
    "=\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\sum_{i=0}^N \\sum_{j=0}^N u_i u_j \\int_\\epsilon^1 x \\varphi_i^{\\prime}(x) \\varphi_j^{\\prime}(x) d x\n",
    "$$\n",
    "\n",
    "**Introducing the matrix $A_{i j}=\\int_\\epsilon^1 x \\varphi_i^{\\prime}(x) \\varphi_j^{\\prime}(x) d x$:**\n",
    "\n",
    "$$\n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\sum_{i=0}^N \\sum_{j=0}^N u_i u_j \\int_\\epsilon^1 x \\varphi_i^{\\prime}(x) \\varphi_j^{\\prime}(x) d x\n",
    "= \n",
    "\\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\sum_{i=0}^N \\sum_{j=0}^N u_i u_j A_{i j}\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minimizing the expresion**\\\n",
    "First we compute the gradient:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial u_k}\\left(\\sum_{i=0}^N \\sum_{j=0}^N u_i u_j A_{i j}\\right)\n",
    "$$\n",
    "\n",
    "- Each term $u_i$ $u_j$ $A_{ij}$ where either $i = k$ or $j = k$ or $i=j=k$ will contribute to the derivative. [Chain Rule!]\n",
    "- The derivative of $u_k$ is 1, and the derivative of any $u_i$ where $i\\neq k$ is $0$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial u_k}\\left(\\sum_{i=0}^N \\sum_{j=0}^N u_i u_j A_{i j}\\right)\n",
    "=\n",
    "2 \\sum_{i=0}^N u_i A_{k i}\n",
    "$$\n",
    "\n",
    "- If we now expand our sum:\n",
    "\n",
    "$$\n",
    "2 \\sum_{i=0}^N u_i A_{k i}\n",
    "=\n",
    "2 u_0 A_{k0} + 2 u_1 A_{k1} + 2 u_2 A_{k2} + \\ldots + 2 u_{N-1} A_{k(N-1)} + 2 u_N A_{kN} \n",
    "$$\n",
    "\n",
    "- The first and last term represent our boundary conditions!\\\n",
    "So we can rewrite the expantion as: \n",
    "\n",
    "$$\n",
    "2 \\sum_{i=0}^N u_i A_{k i}\n",
    "=\n",
    "2 \\sum_{i=1}^{N-1} u_i A_{k i} + 2 u_0 A_{k 0} + 2 u_N A_{k N}\n",
    "$$\n",
    "\n",
    "- We know that our  boundary conditions are $u_0=1$ and $u_N=0$\n",
    "\n",
    "$$\n",
    "2 \\sum_{i=1}^{N-1} u_i A_{k i} + 2 u_0 A_{k 0} + 2 u_N A_{k N}\n",
    "=\n",
    "2 \\sum_{i=1}^{N-1} u_i A_{k i} + 2 A_{k 0}\n",
    "$$\n",
    "\n",
    "To minimize this expression, we set the gradient to zero:\n",
    "$$\n",
    "\\frac{\\partial}{\\partial u_k}\\left(\\sum_{i=0}^N \\sum_{j=0}^N u_i u_j A_{i j}\\right)\n",
    "=\n",
    "2 \\sum_{i=1}^{N-1} u_i A_{k i} + 2 A_{k 0}\n",
    "=\n",
    "0\n",
    "$$\n",
    "\n",
    "$$\n",
    "2 \\sum_{i=1}^{N-1} u_i A_{k i} =- 2 A_{k 0}\n",
    "$$\n",
    "\n",
    "- Divide by $2$:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{N-1} u_i A_{k i} = -A_{k 0}\n",
    "$$\n",
    "\n",
    "This holds for all $ k $ in $ \\{1, \\ldots, N-1\\} $, leading to a system of linear equations to find the minimum of the original integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to minimize an integral that looks like this:\n",
    "\n",
    "$$ \\min _{\\left(u_1, \\ldots, u_{N-1}\\right) \\in \\mathbb{R}^{N-1}} \\int_\\epsilon^1 x\\left(U^{\\prime}(x)\\right)^2 \\mathrm{~d} x $$\n",
    "\n",
    "Here, $ U^{\\prime}(x) $ is the derivative of a function $ U(x) $, and $ u_1, \\ldots, u_{N-1} $ are the parameters we're adjusting to minimize the integral.\n",
    "\n",
    "**Step 1: Understanding $ U^{\\prime}(x) $**\n",
    "\n",
    "- $ U^{\\prime}(x) $ is not just any derivative; it's a special combination of several other functions (let's call them $ \\varphi_i(x) $) and the parameters $ u_i $ we're trying to find.\n",
    "- Think of $ U^{\\prime}(x) $ as a recipe where $ \\varphi_i^{\\prime}(x) $ are the ingredients, and $ u_i $ are how much of each ingredient to use.\n",
    "\n",
    "**Step 2: Substituting and Expanding**\n",
    "\n",
    "- We substitute this 'recipe' into our original problem. This means wherever we see $ U^{\\prime}(x) $, we replace it with the sum of $ u_i \\varphi_i^{\\prime}(x) $.\n",
    "- Then, we expand everything out. Itâ€™s like spreading out all the ingredients on a table to see everything clearly.\n",
    "\n",
    "**Step 3: Defining $ A_{ij} $**\n",
    "\n",
    "- We introduce a new term, $ A_{ij} $, to simplify our equation. $ A_{ij} $ is a way to encapsulate the interaction between two different 'ingredients' $ \\varphi_i^{\\prime}(x) $ and $ \\varphi_j^{\\prime}(x) $ over the range of $ x $ from $ \\epsilon $ to $ 1 $.\n",
    "\n",
    "**Step 4: Minimizing the Expression**\n",
    "\n",
    "- To find the best combination of $ u_i $'s (the best recipe), we use calculus (specifically, a technique called 'gradient descent'). We set the gradient (or the slope) of our expanded equation to zero. This is like adjusting each $ u_i $ until we find the lowest point of our function.\n",
    "  \n",
    "**Step 5: The Final Equation System**\n",
    "\n",
    "- After some mathematical rearranging (considering that $ u_0 = 1 $ and $ u_N = 0 $), we end up with a set of equations that, when solved, give us the best values for each $ u_i $.\n",
    "- These equations look like this: \n",
    "\n",
    "  $$ \\sum_{i=1}^{N-1} u_i A_{ki} = -A_{k0} $$\n",
    "\n",
    "  for $ k = 1, \\ldots, N-1 $.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "- We started with a complex integral to minimize.\n",
    "- We broke down $ U^{\\prime}(x) $ into a simpler form using basis functions $ \\varphi_i(x) $.\n",
    "- We expanded and rearranged our problem into a more manageable form, introducing $ A_{ij} $ to simplify our expressions.\n",
    "- Finally, we used calculus to find the best values for $ u_i $ that minimize our original integral, resulting in a system of linear equations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
